{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AOTTOA2333/silver-train/blob/main/RVC-MAKER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <h1 align=\"center\"><b>Ultimate RVC Maker üéµ</b></h1>\n",
        "<div align=\"center\">\n",
        "\n",
        "A high-quality voice conversion tool focused on experimentation and performance, built upon [Vietnamese-RVC](https://github.com/PhamHuynhAnh16/Vietnamese-RVC), a fork of the original Retrieval-based Voice Conversion (RVC) project.\n",
        "\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "## <h2 align=\"center\">Overview</h2>\n",
        "\n",
        "This notebook provides a streamlined environment to set up and run the Ultimate RVC Maker, including installation, web interface, Google Drive integration, and model uploading to Hugging Face. Follow the cells below to get started.\n",
        "\n",
        "**Resources:**\n",
        "- [Support Discord](https://discord.gg/aihub)\n",
        "- [GitHub Repository](https://github.com/unchCrew/RVC-MAKER.git)\n",
        "- [Terms of Use](https://github.com/unchCrew/RVC-MAKER/blob/main/TERMS_OF_USE.md)\n",
        "\n",
        "**Created by:** [TheNeoDev](https://github.com/TheNeodev)\n",
        "\n",
        "---\n",
        "\n",
        "## <h2 align=\"center\">Acknowledgments</h2>\n",
        "\n",
        "Special thanks to:\n",
        "- **Original RVC Team**: For developing the core Retrieval-based Voice Conversion framework.\n",
        "- **Vietnamese-RVC**: For providing an up-to-date fork used as the base for this project.\n",
        "\n",
        "## <h2 align=\"center\">Disclaimer</h2>\n",
        "\n",
        "By using Ultimate RVC Maker, you agree to:\n",
        "- Comply with ethical and legal standards.\n",
        "- Respect intellectual property and privacy rights.\n",
        "- Avoid harmful or prohibited uses.\n",
        "- Accept full responsibility for any outcomes.\n",
        "\n",
        "Ultimate RVC Maker disclaims liability and reserves the right to amend these terms. See the [Terms of Use](https://github.com/unchCrew/RVC-MAKER/blob/main/TERMS_OF_USE.md) for details."
      ],
      "metadata": {
        "id": "vOlZ8mQ0XMpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -d /content/ -B /content/drive/MyDrive/program.zip\n"
      ],
      "metadata": {
        "id": "yTbNJmTTh_mv",
        "outputId": "33114ab5-c958-498a-d88e-b9193441bc3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/program.zip\n",
            "  inflating: /content/program/.github/ISSUE_TEMPLATE/bug_report.md  \n",
            "  inflating: /content/program/.github/ISSUE_TEMPLATE/feature_request.md  \n",
            "  inflating: /content/program/assets/autopitch/emb_feats.npz  \n",
            "  inflating: /content/program/assets/autopitch/rvc_feats.npz  \n",
            " extracting: /content/program/assets/binary/decrypt.bin  \n",
            "  inflating: /content/program/assets/binary/world.bin  \n",
            "  inflating: /content/program/assets/ico.png  \n",
            "  inflating: /content/program/assets/languages/en-US.json  \n",
            "  inflating: /content/program/assets/languages/vi-VN.json  \n",
            "  inflating: /content/program/assets/logs/mute/f0/mute.wav.npy  \n",
            "  inflating: /content/program/assets/logs/mute/f0_voiced/mute.wav.npy  \n",
            "  inflating: /content/program/assets/logs/mute/sliced_audios/mute32000.wav  \n",
            "  inflating: /content/program/assets/logs/mute/sliced_audios/mute40000.wav  \n",
            "  inflating: /content/program/assets/logs/mute/sliced_audios/mute48000.wav  \n",
            "  inflating: /content/program/assets/logs/mute/sliced_audios_16k/mute.wav  \n",
            "  inflating: /content/program/assets/logs/mute/v1_extracted/mute.npy  \n",
            "  inflating: /content/program/assets/logs/mute/v1_extracted/mute_spin.npy  \n",
            "  inflating: /content/program/assets/logs/mute/v2_extracted/mute.npy  \n",
            "  inflating: /content/program/assets/logs/mute/v2_extracted/mute_spin.npy  \n",
            " extracting: /content/program/assets/models/audioldm2/.gitkerp  \n",
            " extracting: /content/program/assets/models/embedders/.gitkeep  \n",
            " extracting: /content/program/assets/models/predictors/.gitkeep  \n",
            " extracting: /content/program/assets/models/pretrained_custom/.gitkeep  \n",
            " extracting: /content/program/assets/models/pretrained_v1/.gitkeep  \n",
            " extracting: /content/program/assets/models/pretrained_v2/.gitkeep  \n",
            "  inflating: /content/program/assets/models/speaker_diarization/assets/gpt2.tiktoken  \n",
            "  inflating: /content/program/assets/models/speaker_diarization/assets/mel_filters.npz  \n",
            "  inflating: /content/program/assets/models/speaker_diarization/assets/multilingual.tiktoken  \n",
            " extracting: /content/program/assets/models/uvr5/.gitkeep  \n",
            " extracting: /content/program/assets/presets/.gitkeep  \n",
            " extracting: /content/program/assets/weights/init.txt  \n",
            "  inflating: /content/program/assets/youtube/config.txt  \n",
            " extracting: /content/program/audios/.gitattributes  \n",
            "  inflating: /content/program/Contributing.md  \n",
            " extracting: /content/program/dataset/.gitattributes  \n",
            "  inflating: /content/program/docker-compose-amd.yaml  \n",
            "  inflating: /content/program/docker-compose-cpu.yaml  \n",
            "  inflating: /content/program/docker-compose-cuda118.yaml  \n",
            "  inflating: /content/program/docker-compose-cuda128.yaml  \n",
            "  inflating: /content/program/Dockerfile  \n",
            "  inflating: /content/program/Dockerfile.amd  \n",
            "  inflating: /content/program/Dockerfile.cuda118  \n",
            "  inflating: /content/program/Dockerfile.cuda128  \n",
            "  inflating: /content/program/LICENSE  \n",
            "  inflating: /content/program/main/app/app.py  \n",
            "  inflating: /content/program/main/app/core/downloads.py  \n",
            "  inflating: /content/program/main/app/core/editing.py  \n",
            "  inflating: /content/program/main/app/core/f0_extract.py  \n",
            "  inflating: /content/program/main/app/core/inference/inference.py  \n",
            "  inflating: /content/program/main/app/core/inference/separate.py  \n",
            "  inflating: /content/program/main/app/core/inference/tts.py  \n",
            "  inflating: /content/program/main/app/core/model_utils.py  \n",
            "  inflating: /content/program/main/app/core/presets.py  \n",
            "  inflating: /content/program/main/app/core/process.py  \n",
            "  inflating: /content/program/main/app/core/restart.py  \n",
            "  inflating: /content/program/main/app/core/training.py  \n",
            "  inflating: /content/program/main/app/core/ui.py  \n",
            "  inflating: /content/program/main/app/core/utils.py  \n",
            "  inflating: /content/program/main/app/parser.py  \n",
            "  inflating: /content/program/main/app/run_tensorboard.py  \n",
            "  inflating: /content/program/main/app/tabs/downloads/downloads.py  \n",
            "  inflating: /content/program/main/app/tabs/editing/child/audio_editing.py  \n",
            "  inflating: /content/program/main/app/tabs/editing/child/audio_effects.py  \n",
            "  inflating: /content/program/main/app/tabs/editing/child/quirk.py  \n",
            "  inflating: /content/program/main/app/tabs/editing/editing.py  \n",
            "  inflating: /content/program/main/app/tabs/extra/child/convert_model.py  \n",
            "  inflating: /content/program/main/app/tabs/extra/child/f0_extract.py  \n",
            "  inflating: /content/program/main/app/tabs/extra/child/fushion.py  \n",
            "  inflating: /content/program/main/app/tabs/extra/child/read_model.py  \n",
            "  inflating: /content/program/main/app/tabs/extra/child/settings.py  \n",
            "  inflating: /content/program/main/app/tabs/extra/extra.py  \n",
            "  inflating: /content/program/main/app/tabs/inference/child/convert.py  \n",
            "  inflating: /content/program/main/app/tabs/inference/child/convert_tts.py  \n",
            "  inflating: /content/program/main/app/tabs/inference/child/convert_with_whisper.py  \n",
            "  inflating: /content/program/main/app/tabs/inference/child/separate.py  \n",
            "  inflating: /content/program/main/app/tabs/inference/inference.py  \n",
            "  inflating: /content/program/main/app/tabs/training/child/create_dataset.py  \n",
            "  inflating: /content/program/main/app/tabs/training/child/training.py  \n",
            "  inflating: /content/program/main/app/tabs/training/training.py  \n",
            "  inflating: /content/program/main/app/variables.py  \n",
            "  inflating: /content/program/main/configs/config.json  \n",
            "  inflating: /content/program/main/configs/config.py  \n",
            "  inflating: /content/program/main/configs/v1/32000.json  \n",
            "  inflating: /content/program/main/configs/v1/40000.json  \n",
            "  inflating: /content/program/main/configs/v1/48000.json  \n",
            "  inflating: /content/program/main/configs/v2/32000.json  \n",
            "  inflating: /content/program/main/configs/v2/40000.json  \n",
            "  inflating: /content/program/main/configs/v2/48000.json  \n",
            "  inflating: /content/program/main/inference/audioldm2.py  \n",
            "  inflating: /content/program/main/inference/audio_effects.py  \n",
            "  inflating: /content/program/main/inference/conversion/convert.py  \n",
            "  inflating: /content/program/main/inference/conversion/pipeline.py  \n",
            "  inflating: /content/program/main/inference/conversion/utils.py  \n",
            "  inflating: /content/program/main/inference/create_dataset.py  \n",
            "  inflating: /content/program/main/inference/create_index.py  \n",
            "  inflating: /content/program/main/inference/extract.py  \n",
            "  inflating: /content/program/main/inference/preprocess/preprocess.py  \n",
            "  inflating: /content/program/main/inference/preprocess/slicer2.py  \n",
            "  inflating: /content/program/main/inference/separator_music.py  \n",
            "  inflating: /content/program/main/inference/training/data_utils.py  \n",
            "  inflating: /content/program/main/inference/training/losses.py  \n",
            "  inflating: /content/program/main/inference/training/mel_processing.py  \n",
            "  inflating: /content/program/main/inference/training/train.py  \n",
            "  inflating: /content/program/main/inference/training/utils.py  \n",
            "  inflating: /content/program/main/library/algorithm/attentions.py  \n",
            "  inflating: /content/program/main/library/algorithm/autopitch.py  \n",
            "  inflating: /content/program/main/library/algorithm/commons.py  \n",
            "  inflating: /content/program/main/library/algorithm/discriminators.py  \n",
            "  inflating: /content/program/main/library/algorithm/encoders.py  \n",
            "  inflating: /content/program/main/library/algorithm/modules.py  \n",
            "  inflating: /content/program/main/library/algorithm/normalization.py  \n",
            "  inflating: /content/program/main/library/algorithm/onnx_export.py  \n",
            "  inflating: /content/program/main/library/algorithm/residuals.py  \n",
            "  inflating: /content/program/main/library/algorithm/stftpitchshift.py  \n",
            "  inflating: /content/program/main/library/algorithm/synthesizers.py  \n",
            "  inflating: /content/program/main/library/architectures/demucs_separator.py  \n",
            "  inflating: /content/program/main/library/architectures/fairseq.py  \n",
            "  inflating: /content/program/main/library/architectures/mdx_separator.py  \n",
            "  inflating: /content/program/main/library/audioldm2/models.py  \n",
            "  inflating: /content/program/main/library/audioldm2/utils.py  \n",
            "  inflating: /content/program/main/library/generators/hifigan.py  \n",
            "  inflating: /content/program/main/library/generators/mrf_hifigan.py  \n",
            "  inflating: /content/program/main/library/generators/nsf_hifigan.py  \n",
            "  inflating: /content/program/main/library/generators/refinegan.py  \n",
            "  inflating: /content/program/main/library/predictors/CREPE.py  \n",
            "  inflating: /content/program/main/library/predictors/FCPE/attentions.py  \n",
            "  inflating: /content/program/main/library/predictors/FCPE/encoder.py  \n",
            "  inflating: /content/program/main/library/predictors/FCPE/FCPE.py  \n",
            "  inflating: /content/program/main/library/predictors/FCPE/stft.py  \n",
            "  inflating: /content/program/main/library/predictors/FCPE/utils.py  \n",
            "  inflating: /content/program/main/library/predictors/FCPE/wav2mel.py  \n",
            "  inflating: /content/program/main/library/predictors/Generator.py  \n",
            "  inflating: /content/program/main/library/predictors/RMVPE.py  \n",
            "  inflating: /content/program/main/library/predictors/SWIPE.py  \n",
            "  inflating: /content/program/main/library/predictors/WORLD.py  \n",
            "  inflating: /content/program/main/library/speaker_diarization/audio.py  \n",
            "  inflating: /content/program/main/library/speaker_diarization/ECAPA_TDNN.py  \n",
            "  inflating: /content/program/main/library/speaker_diarization/embedding.py  \n",
            "  inflating: /content/program/main/library/speaker_diarization/encoder.py  \n",
            "  inflating: /content/program/main/library/speaker_diarization/features.py  \n",
            "  inflating: /content/program/main/library/speaker_diarization/parameter_transfer.py  \n",
            "  inflating: /content/program/main/library/speaker_diarization/segment.py  \n",
            "  inflating: /content/program/main/library/speaker_diarization/speechbrain.py  \n",
            "  inflating: /content/program/main/library/speaker_diarization/whisper.py  \n",
            "  inflating: /content/program/main/library/torch_amd.py  \n",
            "  inflating: /content/program/main/library/utils.py  \n",
            "  inflating: /content/program/main/library/uvr5_separator/common_separator.py  \n",
            "  inflating: /content/program/main/library/uvr5_separator/separator.py  \n",
            "  inflating: /content/program/main/library/uvr5_separator/spec_utils.py  \n",
            "  inflating: /content/program/main/tools/gdown.py  \n",
            "  inflating: /content/program/main/tools/huggingface.py  \n",
            "  inflating: /content/program/main/tools/mediafire.py  \n",
            "  inflating: /content/program/main/tools/meganz.py  \n",
            "  inflating: /content/program/main/tools/noisereduce.py  \n",
            "  inflating: /content/program/main/tools/pixeldrain.py  \n",
            "  inflating: /content/program/README.md  \n",
            "  inflating: /content/program/requirements.txt  \n",
            "  inflating: /content/program/run_app.bat  \n",
            "  inflating: /content/program/run_install.bat  \n",
            "  inflating: /content/program/SECURITY.md  \n",
            "  inflating: /content/program/tensorboard.bat  \n",
            "  inflating: /content/program/TERMS_OF_USE.md  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio==5.37"
      ],
      "metadata": {
        "id": "pXe8vEXxnZJt",
        "outputId": "1da8c97c-66cb-4bd2-cdcf-3a100f0fb3ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio==5.37\n",
            "  Downloading gradio-5.37.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (4.9.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (0.3.1)\n",
            "Collecting gradio-client==1.10.4 (from gradio==5.37)\n",
            "  Downloading gradio_client-1.10.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (0.33.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (3.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (0.12.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.37) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.4->gradio==5.37) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.4->gradio==5.37) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio==5.37) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio==5.37) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio==5.37) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio==5.37) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio==5.37) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio==5.37) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio==5.37) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio==5.37) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio==5.37) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.37) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.37) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.37) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio==5.37) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio==5.37) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio==5.37) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.37) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.37) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.37) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio==5.37) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.37) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.37) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio==5.37) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio==5.37) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==5.37) (0.1.2)\n",
            "Downloading gradio-5.37.0-py3-none-any.whl (59.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.6/59.6 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.4-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gradio-client, gradio\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.11.0\n",
            "    Uninstalling gradio_client-1.11.0:\n",
            "      Successfully uninstalled gradio_client-1.11.0\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.38.1\n",
            "    Uninstalling gradio-5.38.1:\n",
            "      Successfully uninstalled gradio-5.38.1\n",
            "Successfully installed gradio-5.37.0 gradio-client-1.10.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show gradio"
      ],
      "metadata": {
        "id": "W54bbn26rLAT",
        "outputId": "9bff7d6b-fbae-47e0-fa2c-d646a28414b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: gradio\n",
            "Version: 5.38.1\n",
            "Summary: Python library for easily interacting with trained machine learning models\n",
            "Home-page: https://github.com/gradio-app/gradio\n",
            "Author: \n",
            "Author-email: Abubakar Abid <gradio-team@huggingface.co>, Ali Abid <gradio-team@huggingface.co>, Ali Abdalla <gradio-team@huggingface.co>, Dawood Khan <gradio-team@huggingface.co>, Ahsen Khaliq <gradio-team@huggingface.co>, Pete Allen <gradio-team@huggingface.co>, √ñmer Faruk √ñzdemir <gradio-team@huggingface.co>, Freddy A Boulton <gradio-team@huggingface.co>, Hannah Blair <gradio-team@huggingface.co>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: aiofiles, anyio, brotli, fastapi, ffmpy, gradio-client, groovy, httpx, huggingface-hub, jinja2, markupsafe, numpy, orjson, packaging, pandas, pillow, pydantic, pydub, python-multipart, pyyaml, ruff, safehttpx, semantic-version, starlette, tomlkit, typer, typing-extensions, uvicorn\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "BJeRif5jjL5s",
        "outputId": "e8417e5c-a8dc-4493-d741-ba16d423e356",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Installation completed successfully! (~2 minutes)\n"
          ]
        }
      ],
      "source": [
        "#@title **Install Ultimate RVC Maker**\n",
        "\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "print(\"üë©üèª‚Äçüíª Starting installation...\")\n",
        "\n",
        "# Suppress TensorFlow logging\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "# Clone repository\n",
        "if not os.path.exists('/content/program'):\n",
        "    !git clone https://github.com/unchCrew/RVC-MAKER.git /content/program\n",
        "else:\n",
        "    print(\"Repository already cloned, skipping...\")\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -r /content/program/requirements.txt  > /dev/null 2>&1\n",
        "!pip install pyngrok  > /dev/null 2>&1\n",
        "!pip install torch --index-url https://download.pytorch.org/whl/cu128  > /dev/null 2>&1\n",
        "\n",
        "# Verify installation\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Failed to import PyTorch. Installation may have issues.\")\n",
        "\n",
        "clear_output()\n",
        "print(\"‚úÖ Installation completed successfully! (~2 minutes)\")\n",
        "#@markdown **Note:** Installation typically takes about 2 minutes. If issues arise, check the output for errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIsBEvHaQWMJ",
        "cellView": "form",
        "outputId": "2a6be833-3485-4ee1-a223-7a3ce9a7da57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/program\n",
            "Starting Gradio interface...\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1753549212.524329    2169 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1753549212.534423    2169 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\n",
            "2025-07-26 17:00:16.581 | INFO | app | cuda:0\n",
            "\n",
            "2025-07-26 17:00:16.581 | INFO | app | Starting interface...\n",
            "\n",
            "2025-07-26 17:00:16.581 | INFO | app | Display language set to en-US.\n",
            "\n",
            "2025-07-26 17:00:18.742 | INFO | app | Running Interface On Local Url: 0.0.0.0:7860\n",
            "\n",
            "2025-07-26 17:00:18.742 | INFO | app | Running Interface On Public Url: https://479876cd78749c6b98.gradio.live\n",
            "\n",
            "2025-07-26 17:00:18.742 | INFO | app | Interface loaded successfully after: 13.02s\n",
            "\n",
            "2025-07-26 17:03:28.515 | INFO | ui | Converting voice...\n",
            "Ultimate RVC Maker:\n",
            "Pitch: 0\n",
            "filter radius: 3\n",
            "f0 method: rmvpe\n",
            "f0 method: hubert_base\n",
            "\n",
            "2025-07-26 17:03:32.488 | INFO | convert | Convert Audio 'audios/„Ç´„É©„É°„É´„Ç´„É©„É† - Silence voice vocals.mp3'...\n",
            "Convert Audio:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 6/10 [00:08<00:05,  1.47s/a]"
          ]
        }
      ],
      "source": [
        "#@title **Run Web Interface**\n",
        "#@markdown Launch the Ultimate RVC Maker web interface using your preferred sharing method.\n",
        "\n",
        "import os\n",
        "import threading\n",
        "import time\n",
        "import urllib.request\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from pyngrok import ngrok\n",
        "\n",
        "%cd /content/program\n",
        "\n",
        "#@markdown ### Options\n",
        "#@markdown - **Enable TensorBoard**: Monitor training progress (logs saved in `./assets/logs`).\n",
        "tensorboard = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown - **Sharing Method**: Choose how to access the web interface.\n",
        "method = \"gradio\" #@param [\"gradio\", \"localtunnel\", \"ngrok\"]\n",
        "\n",
        "#@markdown - **Ngrok Token**: Required for ngrok sharing. Get it from [ngrok dashboard](https://dashboard.ngrok.com/get-started/your-authtoken).\n",
        "ngrok_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "def start_gradio():\n",
        "    print(\"Starting Gradio interface...\")\n",
        "    !python main/app/app.py --share\n",
        "\n",
        "def start_localtunnel():\n",
        "    print(\"Starting localtunnel...\")\n",
        "    !npm install -g localtunnel &>/dev/null\n",
        "    with open('url.txt', 'w') as file:\n",
        "        file.write('')\n",
        "    get_ipython().system_raw('lt --port 7860 >> url.txt 2>&1 &')\n",
        "    time.sleep(3)\n",
        "    try:\n",
        "        endpoint_ip = urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip()\n",
        "        with open('url.txt', 'r') as file:\n",
        "            tunnel_url = file.read().replace(\"your url is: \", \"\").strip()\n",
        "        print(f\"Share Link: \\033[93m{tunnel_url}\\033[0m\")\n",
        "        display(widgets.Text(value=endpoint_ip, description='Password IP:', disabled=True))\n",
        "        !python main/app/app.py\n",
        "    except Exception as e:\n",
        "        print(f\"Error starting localtunnel: {e}\")\n",
        "\n",
        "def start_ngrok():\n",
        "    if not ngrok_token:\n",
        "        print(\"‚ö†Ô∏è Ngrok token is required. Please provide a valid token.\")\n",
        "        return\n",
        "    try:\n",
        "        ngrok.set_auth_token(ngrok_token)\n",
        "        ngrok.kill()\n",
        "        tunnel = ngrok.connect(7860)\n",
        "        print(f\"Ngrok URL: \\033[93m{tunnel.public_url}\\033[0m\")\n",
        "        !python main/app/app.py --listen\n",
        "    except Exception as e:\n",
        "        print(f\"Error starting ngrok: {e}\")\n",
        "\n",
        "def start_app():\n",
        "    try:\n",
        "        if method == \"gradio\":\n",
        "            start_gradio()\n",
        "        elif method == \"localtunnel\":\n",
        "            start_localtunnel()\n",
        "        elif method == \"ngrok\":\n",
        "            start_ngrok()\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to start application: {e}\")\n",
        "\n",
        "# Start TensorBoard if enabled\n",
        "if tensorboard:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir ./assets/logs --port=6870\n",
        "\n",
        "# Start application in a separate thread\n",
        "thread_app = threading.Thread(target=start_app)\n",
        "thread_app.start()\n",
        "\n",
        "# Keep the cell running\n",
        "while True:\n",
        "    time.sleep(5)\n",
        "\n",
        "#@markdown **Note:** Use the interface for full functionality. If using TensorBoard, check for overtraining in the logs."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra"
      ],
      "metadata": {
        "id": "ePr9otBuAZBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Mount Google Drive**\n",
        "#@markdown Mount Google Drive to store or access files for Ultimate RVC Maker.\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "try:\n",
        "    drive.mount(\"/content/drive\", force_remount=False)\n",
        "    print(\"‚úÖ Google Drive mounted successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Failed to mount Google Drive: {e}\")\n",
        "\n",
        "#@markdown **Note:** Ensure you have sufficient space in Google Drive for backups."
      ],
      "metadata": {
        "cellView": "form",
        "id": "iVmOpUn2xhe_",
        "outputId": "0044a630-bf9c-40c8-8a4a-94cef43d6a04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Google Drive mounted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Toggle Auto Backup**\n",
        "#@markdown Enable or disable automatic backups to Google Drive. Backups save logs from `/content/program/assets/logs` to `/content/drive/MyDrive/RVCBackup`.\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import threading\n",
        "\n",
        "LOGS_FOLDER = \"/content/program/assets/logs\"\n",
        "GOOGLE_DRIVE_PATH = \"/content/drive/MyDrive/RVCBackup\"\n",
        "\n",
        "if \"autobackups\" not in globals():\n",
        "    autobackups = False\n",
        "\n",
        "#@markdown **Backup Cooldown**: Time (in seconds) between checks when files are up to date.\n",
        "cooldown = 15 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "\n",
        "def backup_files():\n",
        "    if not os.path.exists(GOOGLE_DRIVE_PATH):\n",
        "        print(f\"‚ö†Ô∏è Google Drive not mounted at {GOOGLE_DRIVE_PATH}. Please run the 'Mount Google Drive' cell first.\")\n",
        "        return\n",
        "\n",
        "    print(\"Starting backup loop...\")\n",
        "    last_backup_timestamps_path = os.path.join(LOGS_FOLDER, \"last_backup_timestamps.txt\")\n",
        "    fully_updated = False\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            updated_files, deleted_files, new_files = 0, 0, 0\n",
        "            last_backup_timestamps = {}\n",
        "\n",
        "            # Load previous timestamps\n",
        "            try:\n",
        "                with open(last_backup_timestamps_path, \"r\") as f:\n",
        "                    last_backup_timestamps = {k: float(v) for k, v in (line.strip().split(\":\", 1) for line in f)}\n",
        "            except FileNotFoundError:\n",
        "                pass\n",
        "\n",
        "            # Backup new or updated files\n",
        "            for root, dirs, files in os.walk(LOGS_FOLDER):\n",
        "                dirs[:] = [d for d in dirs if d not in (\"zips\", \"mute\")]\n",
        "                for filename in files:\n",
        "                    if filename != \"last_backup_timestamps.txt\":\n",
        "                        filepath = os.path.join(root, filename)\n",
        "                        if os.path.isfile(filepath):\n",
        "                            backup_filepath = os.path.join(GOOGLE_DRIVE_PATH, os.path.relpath(filepath, LOGS_FOLDER))\n",
        "                            os.makedirs(os.path.dirname(backup_filepath), exist_ok=True)\n",
        "                            current_timestamp = os.path.getmtime(filepath)\n",
        "                            last_backup_timestamp = last_backup_timestamps.get(filepath)\n",
        "                            if last_backup_timestamp is None or last_backup_timestamp < current_timestamp:\n",
        "                                shutil.copy2(filepath, backup_filepath)\n",
        "                                last_backup_timestamps[filepath] = current_timestamp\n",
        "                                if last_backup_timestamp is None:\n",
        "                                    new_files += 1\n",
        "                                else:\n",
        "                                    updated_files += 1\n",
        "\n",
        "            # Remove deleted files from backup\n",
        "            for filepath in list(last_backup_timestamps.keys()):\n",
        "                if not os.path.exists(filepath):\n",
        "                    backup_filepath = os.path.join(GOOGLE_DRIVE_PATH, os.path.relpath(filepath, LOGS_FOLDER))\n",
        "                    if os.path.exists(backup_filepath):\n",
        "                        os.remove(backup_filepath)\n",
        "                        deleted_files += 1\n",
        "                    del last_backup_timestamps[filepath]\n",
        "\n",
        "            # Log backup status\n",
        "            if new_files > 0 or updated_files > 0 or deleted_files > 0:\n",
        "                print(f\"Backup Complete: {new_files} new, {updated_files} updated, {deleted_files} deleted.\")\n",
        "                fully_updated = False\n",
        "            elif not fully_updated:\n",
        "                print(\"Files are up to date.\")\n",
        "                fully_updated = True\n",
        "\n",
        "            # Save timestamps\n",
        "            with open(last_backup_timestamps_path, \"w\") as f:\n",
        "                for filepath, timestamp in last_backup_timestamps.items():\n",
        "                    f.write(f\"{filepath}:{timestamp}\\n\")\n",
        "\n",
        "            time.sleep(cooldown if fully_updated else 0.1)\n",
        "\n",
        "        except Exception as error:\n",
        "            print(f\"Error during backup: {error}\")\n",
        "            time.sleep(5)\n",
        "\n",
        "# Toggle autobackup\n",
        "if autobackups:\n",
        "    autobackups = False\n",
        "    print(\"‚úÖ Autobackup disabled.\")\n",
        "else:\n",
        "    autobackups = True\n",
        "    print(\"‚úÖ Autobackup enabled.\")\n",
        "    threading.Thread(target=backup_files, daemon=True).start()\n",
        "\n",
        "#@markdown **Note:** Ensure Google Drive is mounted before enabling backups. The backup runs in the background and checks for changes every 0.1s (or `cooldown` seconds when up to date)."
      ],
      "metadata": {
        "cellView": "form",
        "id": "7PoT_1qCxlLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Upload Model to Hugging Face**\n",
        "#@markdown Upload your trained model and index file to a Hugging Face repository.\n",
        "\n",
        "import huggingface_hub\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "#@markdown **Repository ID**: Format as `username/repo_name`.\n",
        "repo_hf = \"NeoPy/TTS-G\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **Model Path**: Path to the `.pth` model file.\n",
        "pth = \"/content/program/assets/weights/TTS_100e_500s.pth\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **Index Path**: Path to the `.index` file.\n",
        "index = \"/content/program/assets/logs/TTS/added_IVF59_Flat_nprobe_1_TTS_v2.index\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **Hugging Face Token**: Get it from [Hugging Face settings](https://huggingface.co/settings/tokens).\n",
        "token = \"hf_\" #@param {type:\"string\"}\n",
        "\n",
        "def upload_model(repo, pth, index, token):\n",
        "    try:\n",
        "        # Validate inputs\n",
        "        if not repo or '/' not in repo:\n",
        "            return \"‚ùå Invalid repository ID. Use format: username/repo_name\"\n",
        "        if not token.startswith(\"hf_\"):\n",
        "            return \"‚ùå Invalid Hugging Face token. It should start with 'hf_'\"\n",
        "        if not os.path.exists(pth):\n",
        "            return f\"‚ùå Model file not found at {pth}\"\n",
        "        if not os.path.exists(index):\n",
        "            return f\"‚ùå Index file not found at {index}\"\n",
        "\n",
        "        # Create README\n",
        "        repo_name = repo.split('/')[-1]\n",
        "        readme = f\"\"\"\n",
        "# {repo_name}\n",
        "This model was trained and uploaded using [Ultimate RVC Maker](https://github.com/unchCrew/RVC-MAKER) by [TheNeoDev](https://github.com/TheNeodev).\n",
        "        \"\"\"\n",
        "\n",
        "        # Create zip file\n",
        "        zip_path = f\"{repo_name}.zip\"\n",
        "        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "            zipf.write(pth, os.path.basename(pth))\n",
        "            zipf.write(index, os.path.basename(index))\n",
        "            zipf.writestr('README.md', readme)\n",
        "\n",
        "        # Upload to Hugging Face\n",
        "        api = huggingface_hub.HfApi()\n",
        "        api.create_repo(repo_id=repo, token=token, exist_ok=True)\n",
        "        api.upload_file(\n",
        "            path_or_fileobj=zip_path,\n",
        "            path_in_repo=f\"{repo_name}.zip\",\n",
        "            repo_id=repo,\n",
        "            token=token\n",
        "        )\n",
        "\n",
        "        # Clean up\n",
        "        os.remove(zip_path)\n",
        "        return \"‚úÖ Model uploaded successfully to Hugging Face!\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error uploading model: {e}\"\n",
        "\n",
        "# Execute upload\n",
        "print(upload_model(repo_hf, pth, index, token))\n",
        "\n",
        "#@markdown **Note:** Ensure the model and index files exist at the specified paths. The upload creates a zip file containing both files and a README."
      ],
      "metadata": {
        "cellView": "form",
        "id": "Y1Jke8epTHFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Clean Up Temporary Files**\n",
        "#@markdown Remove temporary files to free up space in the Colab environment.\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def clean_temp_files():\n",
        "    temp_dirs = ['/content/program', '/content/url.txt']\n",
        "    freed_space = 0\n",
        "    for path in temp_dirs:\n",
        "        try:\n",
        "            if os.path.isfile(path):\n",
        "                size = os.path.getsize(path) / (1024 * 1024)  # Size in MB\n",
        "                os.remove(path)\n",
        "                freed_space += size\n",
        "                print(f\"Removed file: {path}\")\n",
        "            elif os.path.isdir(path):\n",
        "                size = sum(os.path.getsize(os.path.join(root, f)) for root, _, files in os.walk(path) for f in files) / (1024 * 1024)\n",
        "                shutil.rmtree(path, ignore_errors=True)\n",
        "                freed_space += size\n",
        "                print(f\"Removed directory: {path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error removing {path}: {e}\")\n",
        "    return f\"‚úÖ Cleaned up temporary files. Freed approximately {freed_space:.2f} MB.\"\n",
        "\n",
        "print(clean_temp_files())\n",
        "\n",
        "#@markdown **Warning:** This will delete the `/content/program` directory and other temporary files. Ensure you have backed up important data."
      ],
      "metadata": {
        "cellView": "form",
        "id": "R1em4cPRxh4W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}